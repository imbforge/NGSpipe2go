---
title: "SHINYREPS_PROJECT"
output:
  html_document:
    toc: true
    toc_float: true
    css: styles.css
---

<div class="contentbox">


# Description

Enter project description here


```{r setup, echo=F, result='hide', error=F, warning=F, message=F}

library(ggplot2)
# source helper functions
source("sc.shinyrep.helpers.R")


# load global variables
loadGlobalVars(f="shinyReports.txt")
runCutadapt <- SHINYREPS_RUN_CUTADAPT=="true" # check for selected pipeline modules 

knitr::opts_chunk$set(cache=F,
                      echo=F,
                      warning=F,
                      message=F,
                      dev='CairoPNG')

targets_pools <- read.delim(SHINYREPS_TARGET, sep="\t", comment.char = "#")
switch(SHINYREPS_SEQTYPE,
       tenX={
      # in case of hto multiplexing targets_pools is collapsed to (not de-multiplexed) fastq files for the fastq-file level QC plots (targets4plots).
      # But 'group' and 'replicate' columns are not kept if they show multiple values per file (e.g. multiplexed samples belong to different groups). 
      # This is only relevant for the gene body coverage plots per group or per replicate, which would be misleading in that case.
      collapsedColumns <- sapply(c("sample", "group", "replicate"), function(x) {
          all(sapply(unique(targets_pools$file), function(y) {length(unique(targets_pools[targets_pools$file==y, x]))==1}))
          })
      targets4plots <- targets_pools[!duplicated(targets_pools$file), c("file", names(collapsedColumns)[collapsedColumns])] 
      if(!"sample" %in% colnames(targets4plots)) {targets4plots$sample <- targets4plots$file} # "sample" column is needed. Same as "file" if ambiguous.
       },
      ScaleBio={      
        targets4plots <- targets_pools |> # summarize multiple rows per file for fastq-centered QC plots
        group_by(file) |>
        summarise(across(everything(), ~ paste(unique(.), collapse = ", "))) |>
        as.data.frame()
},
      ParseBio={
        targets4plots <- targets_pools |> # summarize multiple rows per file for fastq-centered QC plots
        group_by(file) |>
        summarise(across(everything(), ~ paste(unique(.), collapse = ", "))) |>
        as.data.frame()

      },
      SmartSeq={
        targets4plots <- targets
      }
)


# print targets pools
DT::datatable(targets4plots, caption="targets file (sample sheet) used for analysis")

```

# Quality control of raw reads #

## FastQC of all reads

The raw sequence reads of all samples are analysed with the popular FastQC tool (http://www.bioinformatics.babraham.ac.uk/projects/fastqc/).

#### Read quality

The "read qualities" plot summarizes the mean quality score at each position.
The color on the graph shows the Phred quality scores, which are logarithmically related to the base-calling error probabilities. The higher the score the better the base call. The background of the graph divides the y axis into very good quality calls (green), calls of reasonable quality (yellow), and calls of poor quality (red). Typically, the majority of calls on all base positions fall into the green area. Due to binning of quality score in recent sequencing technologies (e.g. Illumina NextSeq), sequencing qualities are the same on many position and, thus, also samples appear to have very similar or almost identical sequencing qualities.


```{r FastQC_qual_summarized, echo=F,results='asis',error=F,warning=F,message=F,fig.align='center'}
##### parameters to set:
# Select samples for which you would like to include fastqc results in the report. For single cell RNA-Seq with many cells, 
# you may want to restrict the total number of plots. If you provide a regular expression in 'samplePattern' only those 
# filenames will be included which match this expression, e.g. setting samplePattern="R1" yields only those fastq 
# files containing read1 of a read pair. This is recommended e.g. for MARS-Seq, where Read2 contains barcode information only.
# If you want to exclude samples according to the given certain pattern, define it in excludePattern. 
# If you set argument 'maxno', the maximum sample number will be restricted accordingly to the first 'maxno' plots. 
##### 

if (SHINYREPS_FASTQC_SUMMARIZED) {
    fastqc_summary_plot <- DEhelper.Fastqc.custom(web=F,summarizedPlots=T, targetsdf=targets4plots, samplePattern=SHINYREPS_SAMPLEPATTERN1, excludePattern=SHINYREPS_SAMPLEPATTERN2, maxno=SHINYREPS_MAXNO)
    plot(fastqc_summary_plot$p.qual)
    cat("\n", fill = T)
} else {
    fastqc_summary_plot <- DEhelper.Fastqc.custom(web=F,summarizedPlots=F, targetsdf=targets4plots, samplePattern=SHINYREPS_SAMPLEPATTERN1, excludePattern=SHINYREPS_SAMPLEPATTERN2, maxno=SHINYREPS_MAXNO)
}

```

```{r FastQC_qual, echo=F,results='asis',error=F,warning=F,message=F,fig.align='center',fig.height=min(170, round((3*fastqc_summary_plot$no.of.samples)/4)+1)}
# REMARK: the maximal figure height is limited to 170 and will throw an error if exceeded ("Failed to create Cairo backend!"). For the not summarized plots you should limit the number of plots to 200 by using the maxno parameter. Otherwise the plots will be squeezed.

if (SHINYREPS_FASTQC_SUMMARIZED == FALSE) {
    plot(fastqc_summary_plot$p.qual)
    cat("\n", fill = T)
}

```

#### Sequence bias

The "sequence bias" plot shows the proportion of each base (% G, A, T and C) at each position. In a random library there would be little difference between the positions of a sequence run, so the lines in this plot should run parallel with each other. But most RNA-seq libraries show sequence imbalance in the first 10-12 read positions due to RT priming biases, which should however look fairly similar in all samples. In case the nucleotide content is summarized in a heatmap for all samples, gray colored fields represent a balanced nucleotide content.

```{r FastQC_nuc_content_summarized, echo=F,results='asis',error=F,warning=F,message=F,fig.align='center', fig.height=min(170, ceiling(0.12*fastqc_summary_plot$no.of.samples)+1)}

if (SHINYREPS_FASTQC_SUMMARIZED) {
    plot(fastqc_summary_plot$p.content)
    cat("\n", fill = T)
} 

```

```{r FastQC_nuc_content, echo=F,results='asis',error=F,warning=F,message=F,fig.align='center',fig.height=min(170, round((3*fastqc_summary_plot$no.of.samples)/4)+1)}

if (SHINYREPS_FASTQC_SUMMARIZED == F) {
    plot(fastqc_summary_plot$p.content)
    cat("\n", fill = T)
}
```

#### GC content

The "GC content" plot shows the GC% distribution of all reads and all samples. Typically, the lines should tightly overlap and look essentially the same in all samples. An unusually shaped distribution could indicate a contaminated library.

```{r FastQC_GC, echo=F,results='asis',error=F,warning=F,message=F,fig.align='center'}

fastqc_summary_plot$p.gc
cat("\n", fill = T)
```



```{r cutadapt, echo=F, results='asis', error=F, warning=F, message=F, eval=runCutadapt}
##### parameters to set:
# define subset of cutadapt log files if desired (samplePattern=NULL (default) includes all files).
# define categories of targets.txt to be used for dot color in the plot (one plot per element of colorByFactor will be created). 
# The function will try to map the data from targets$file to the cutadapt log file names (for this, the unique part of 
# targets$file must be a substring of file name). If you have cutadapt log files from pooled fastq files but cell-wise 
# information in targets.txt as in MARS-Seq, you may provide another customized targets object in 'targetsdf'. 
# Otherwise pruned file names will be used by default.
#####

cat("## Adapter trimming with Cutadapt\n")

cat("\nThe following plot shows the amount of reads trimmed for the selected adapter sequences including polyA/polyT sequences if specified. The column 'tooshort' gives the percentage of reads removed due to a length of less than 30 bases after trimming. Additionally to the column 'trimmed' which is for all adapters combined, there are columns for every single adapter giving the percentage of reads trimmed for this adapter.\n\n")

DEhelper.cutadapt(colorByFactor=colorByFactor, targetsdf=targets4plots)
```

```{r FastQC_qual_summarized_trimmed, echo=F,results='asis',error=F,warning=F,message=F,fig.align='center', eval=runCutadapt}
cat("### FastQC of trimmed reads QC\n\n")
cat("#### Read quality\n\n")
if (SHINYREPS_FASTQC_SUMMARIZED) {
    fastqc_summary_plot <- DEhelper.Fastqc.custom(web=F,summarizedPlots=T, subdir="trimmed", targetsdf=targets4plots, samplePattern=SHINYREPS_SAMPLEPATTERN1, excludePattern=SHINYREPS_SAMPLEPATTERN2, maxno=SHINYREPS_MAXNO)
    plot(fastqc_summary_plot$p.qual)
    cat("\n", fill = T)
} else {
    fastqc_summary_plot <- DEhelper.Fastqc.custom(web=F,summarizedPlots=F, subdir="trimmed", targetsdf=targets4plots, samplePattern=SHINYREPS_SAMPLEPATTERN1, excludePattern=SHINYREPS_SAMPLEPATTERN2, maxno=SHINYREPS_MAXNO)
}
```

```{r FastQC_qual_trimmed, echo=F,results='asis',error=F,warning=F,message=F,fig.align='center',fig.height=min(170, round((3*fastqc_summary_plot$no.of.samples)/4)+1), eval=runCutadapt}

if (SHINYREPS_FASTQC_SUMMARIZED == FALSE) {
    plot(fastqc_summary_plot$p.qual)
    cat("\n", fill = T)
}
```

```{r FastQC_nuc_content_summarized_trimmed, echo=F,results='asis',error=F,warning=F,message=F,fig.align='center', fig.height=min(170, ceiling(0.12*fastqc_summary_plot$no.of.samples)+1), eval=runCutadapt}
cat("#### Sequence bias of trimmed reads\n")

if (SHINYREPS_FASTQC_SUMMARIZED) {
    plot(fastqc_summary_plot$p.content)
    cat("\n", fill = T)
} 
```

```{r FastQC_nuc_content_trimmed, echo=F,results='asis',error=F,warning=F,message=F,fig.align='center',fig.height=min(170, round((3*fastqc_summary_plot$no.of.samples)/4)+1), eval=runCutadapt}

if (SHINYREPS_FASTQC_SUMMARIZED == F) {
    plot(fastqc_summary_plot$p.content)
    cat("\n", fill = T)
}
```

```{r FastQC_GC_trimmed, echo=F,results='asis',error=F,warning=F,message=F,fig.align='center', eval=runCutadapt}
cat("#### GC content of trimmed reads\n")
fastqc_summary_plot$p.gc
cat("\n", fill = T)
```

# Quality control of read alignment #

## Gene body coverage ##

The plots below show meta-gene profiles of 5' to 3' read coverage and can reveal biases due to RNA degradation or specific library prep protocol; polyA-selection protocols are particularly prone of producing 3' coverage bias upon RNA degradation.

```{r GeneBodyCoverage_paragraph, echo=F, error=F, warning=F, message=F, results='asis', fig.align="center"}

plot_list <- DEhelper.geneBodyCov2(web=F, targetsdf=targets4plots, samplePattern=SHINYREPS_SAMPLEPATTERN1, excludePattern=SHINYREPS_SAMPLEPATTERN2, maxno=SHINYREPS_MAXNO)

cat("#### Gene body coverage per sample: plotly")
cat("\n\n", fill=T)
plot_list$plotly |>
    plotly::highlight(dynamic=T, selectize=T, persistent=T, selected = plotly::attrs_selected(showlegend = FALSE)) 
cat("\n\n")

if("p_per_sample" %in% names(plot_list)){
   cat("#### Gene body coverage per sample: \n", fill=T)
   if("p_per_cells" %in% names(plot_list)) {
     plot(plot_list$p_per_cells) # for plate-based approaches use plot colored by cell control type if available
   } else {
   plot(plot_list$p_per_sample)
   }
   cat("\n", fill=T)
}

if("num_groups" %in% names(plot_list)) {
   no.of.groups <- plot_list$num_groups
} else {
   no.of.groups <- 1
}

if("num_replicates" %in% names(plot_list)) {
   no.of.replicates <- plot_list$num_replicates
} else {
   no.of.replicates <- 1
}

```

```{r GeneBodyCoverage_splitByGroup, echo=F, error=F, warning=F, message=F, results='asis', fig.align="center", out.width="100%", fig.height=ceiling((no.of.groups)/2)*3+0.5+ifelse(no.of.groups<2,2,0)}

if(("p_per_sample_splitByGroup" %in% names(plot_list)) && !("p_per_cells_splitByGroup" %in% names(plot_list))){
   cat("#### Gene body coverage per sample split by group: \n", fill=T)
   plot(plot_list$p_per_sample_splitByGroup)
   cat("\n", fill=T)
}
if("p_per_replicate_splitByGroup" %in% names(plot_list)){
  cat("#### Gene body coverage per sample split by group, colored by replicate: \n", fill=T)
  plot(plot_list$p_per_replicate_splitByGroup)
  cat("\n", fill=T)
}
if("p_per_cells_splitByGroup" %in% names(plot_list)){
  cat("#### Gene body coverage per sample split by group, colored by cell control type: \n", fill=T)
  plot(plot_list$p_per_cells_splitByGroup)
  cat("\n", fill=T)
}
```


```{r GeneBodyCoverage_splitByReplicate, echo=F, error=F, warning=F, message=F, results='asis', fig.align="center", out.width="100%", fig.height=ceiling((no.of.replicates)/2)*3+0.5+ifelse(no.of.replicates<2,2,0)}
if("p_per_group_splitByReplicate" %in% names(plot_list)){
  cat("#### Gene body coverage per sample split by replicate, colored by group: \n", fill=T)
  plot(plot_list$p_per_group_splitByReplicate)
  cat("\n", fill=T)
}
```


```{r GeneBodyCoverage_splitByGroupReplicate, echo=F, error=F, warning=F, message=F, results='asis', fig.align="center", out.width="100%", fig.height=ceiling((no.of.replicates*no.of.groups)/2)*3+0.5+ifelse(no.of.replicates*no.of.groups<2,2,0)}
if("p_per_cells_splitByGroupReplicate" %in% names(plot_list)){
  cat("#### Gene body coverage per sample split by group and replicate, colored by cell control type: \n", fill=T)
  plot(plot_list$p_per_cells_splitByGroupReplicate)
  cat("\n", fill=T)
}
```



```{r strandspecificity,  echo=F, results='asis', error=F, warning=F, message=F}
cat("## Strand specificity\n")

cat("\nThe table below shows the fraction of reads mapped in sense or antisense to gene exons - around 0.5 for non-stranded library prep protocols and close to 0 or 1 for strand-specific RNA-seq protocols. The strandedness is calculated as the percentage of unambiguous reads that are on the strand, which is expected by the library preparation protocol.\n\n")

DEhelper.strandspecificity(samplePattern=SHINYREPS_SAMPLEPATTERN1, targetsdf=targets4plots, excludePattern=SHINYREPS_SAMPLEPATTERN2, maxno=SHINYREPS_MAXNO)
```


## Qualimap

Illustrate genomic origin of reads

```{r Qualimap, fig.height=min(170, ceiling(0.12*fastqc_summary_plot$no.of.samples)+1)}
DEhelper.Qualimap(targetsdf=targets4plots, samplePattern=SHINYREPS_SAMPLEPATTERN1, excludePattern=SHINYREPS_SAMPLEPATTERN2, maxno=SHINYREPS_MAXNO)
```


## RNA class representation ##

The following plot shows the fraction of reads assigned to various RNA classes. These plots help in determining if the sample prep protocol worked well and may reveal issues with rRNA contamination. 

```{r RNAtypes_paragraph, echo=F, results='asis', error=F, warning=F, message=F, fig.height=min(170, ceiling(0.12*fastqc_summary_plot$no.of.samples)+1)}
DEhelper.RNAtypes(targetsdf=targets4plots, samplePattern=SHINYREPS_SAMPLEPATTERN1, excludePattern=SHINYREPS_SAMPLEPATTERN2, maxno=SHINYREPS_MAXNO)
```


# Mapping Statistics

```{r STAR_paragraph_violin, results='asis'}
##### parameters to set:
# You can define columns of targets.txt to be used for dot color in the summary plot (one plot per element of colorByFactor will be created). 
# The function will try to map the data from targets$file to the STAR log file names (for this, the unique part of 
# targets$file must be a substring of the file name). If you have STAR log files from pooled fastq files but cell-wise 
# information in targets.txt as in MARS-Seq, you may provide another customized targets object in 'targetsdf'. 
# Otherwise pruned file names will be used by default.
#####

switch(SHINYREPS_SEQTYPE,
       tenX={
         # to be implemented
         print("Mapping Statistics can be found in the respective web summary provided by manufacturer.")
       },
       ParseBio={
         # to be implemented
         print("Mapping Statistics can be found in the respective web summary provided by manufacturer.")
       },
       ScaleBio={
             pathMappingStats <- file.path(SHINYREPS_MAPPINGSTATS)

             if(file.exists(pathMappingStats)) {
               mappingStats <- readr::read_csv(pathMappingStats) |>
                 dplyr::filter(Category != "Extrapolated Complexity") |>
                 dplyr::rename_with(stringr::str_remove("\\.ScaleRNA"))
               print(kableExtra::kbl(mappingStats, caption="Mapping Statistics after processing with proprietary software from manufacturer", row.names=F, format="simple", align = "l") |> kableExtra::kable_styling())
                 } else {
                    print("Mapping Statistics can be found in the respective web summary provided by manufacturer.")
                 }
       },
       SmartSeq={
           print("The mapping statistics below show the number input raw reads and percentages of uniquely mapped reads, multi-mapped reads aligning equally well to multiple (up to 10) positions in the genome and overall mapped reads. For the multimapped reads, one random alignment among the best mapping positions is retained.\n")
           star_stats_violin <- DEhelper.STAR.violin(targetsdf=targets4plots)
           cat("\n#### Mapping summary\n", fill=T)
             for(i in 1:length(star_stats_violin$p_mapped)){
               grid.arrange(grobs=star_stats_violin$p_mapped[[i]], layout_matrix= matrix(c(1,2), nrow=1)) 
             }
           cat("\n", fill = T)
           cat("\n#### Mapping statistics\n", fill=T)
           star_stats_violin$stat
       }
)


```



```{r umicount, results='asis', eval= (SHINYREPS_SEQTYPE=="MARSseq")}
##### parameters to set:
# define subset of umicount log files if desired (samplePattern=NULL (default) includes all files).
# define categories of targets.txt to be used for dot color in the plot (one plot per element will be created). 
# The function will try to map the data from targets$file to the umicount log file names (for this, the unique part of 
# targets$file must be a substring of the file name). If you have umi-tools log files from pooled fastq files but cell-wise 
# information in targets.txt as in MARS-Seq, you may provide another customized targets object in 'targetsdf'. 
# Otherwise pruned file names will be used by default.
#####
if(SHINYREPS_SEQTYPE=="MARSseq") {
cat("## Read de-duplication and feature counting with UMI-tools

UMI-tools counts the mapped reads per feature obtained after de-duplication. UMI-tools uses the uniquely mapped reads from STAR as well as as the multimapped reads (but not those which are mapped to too many loci) as input reads.")

DEhelper.umicount(targetsdf=targets4plots)
}
```


## Competetive mapping to rRNAs and other contaminants:

A competitive mapping to the reference genome and known rRNAs (H. sapiens, M. musculus, C. elegans, D. melanogaster, D. rerio, X. tropicalis) as well as frequently occurring Mycoplasma species (M. arginini, M. fermentans, M. hominis, M. hyorhinis, M. orale, and Acholeplasma laidlawii), PhiX and ERCC spike-in sequences, E. coli and B. taurus (bovine) was performed with FastQScreen (http://www.bioinformatics.babraham.ac.uk/projects/fastq_screen/).

In the following plot only relevant contaminants are shown. A contaminant is considered relevant if it consumes `r SHINYREPS_FASTQSCREEN_PERC`% of reads or more in at least one sample. The "one genome" label refers to the amount of reads mapping to that genome only, no matter if they are mapping uniquely or multiple times. The "multiple genome" label refers to the amount of read mapping to this genome but also to other genomes in the screening regardless of whether they are uniquely or multi mapping. 

```{r fastqscreen_paragraph, results='asis', fig.width=10, error=F}
fastqscreen_plots <- DEhelper.fastqscreen(perc.to.plot=SHINYREPS_FASTQSCREEN_PERC, ncol=3, targetsdf=targets4plots, samplePattern=SHINYREPS_SAMPLEPATTERN1, excludePattern=SHINYREPS_SAMPLEPATTERN2, maxno=SHINYREPS_MAXNO)
```

```{r fastqscreen_paragraph2, echo=F,results='asis',error=F,warning=F,message=F,fig.align='center', fig.height=min(170, (round((1.5*fastqscreen_plots$no.of.rows))+1)*fastqscreen_plots$no.of.samples/8+1)}
  if(is.null(fastqscreen_plots$errortext)) {
    plot(fastqscreen_plots$p.category.wrap)
    } else {
      cat(fastqscreen_plots$errortext)
      }
```


## UCSC Genome Browser tracks ##

The browser tracks are generated using bamCoverage tool in [deepTools](https://deeptools.readthedocs.io/en/develop/) and they are normalized using the Counts Per Million mapped reads (CPM) method. Both unique and multi-mapped reads are included in the generation of browser coverage tracks.

To view the tracks in the UCSC Genome Browser, navigate to the [UCSC Genome Browser Track Hub page](https://genome-euro.ucsc.edu/cgi-bin/hgHubConnect) and enter the following line into the `URL` field:

```{r Trackhub, results='asis', error=F}
cat(DEhelper.Trackhub(), sep="\n")
```



# Analysis of single-cell data


```{r demux_HTO, results='asis', eval=!is.na(SHINYREPS_RUN_DEMUX) && SHINYREPS_RUN_DEMUX=="demux_HTO"}

cat("## De-Multiplexing Cell Hashing\n\n")

cat("\nSample multiplexing was applied using cell hashing. After cellranger analysis, the samples were demultiplexed using cite_seq_count and Seurat as outlined here: https://satijalab.org/seurat/articles/hashing_vignette.html. Only mapped singlets are used for downstream processing (note that doublets consisting of multiple cells of the same hashtag can not be identified here).\n")

dirnamePlot <- file.path(SHINYREPS_DEMUX_OUT, list.files(SHINYREPS_DEMUX_OUT), "Seurat")
for (i in 1:length(dirnamePlot)) {
  cat(paste("\n\n### Demultiplexing for", list.files(SHINYREPS_DEMUX_OUT)[i], "\n\n"))

  load(file.path(dirnamePlot[i], "infoNote.RData"))
  print(kableExtra::kbl(as.data.frame(infoNote[["counts per hashtag"]]), caption="Counts per hashtag", row.names=T, col.names=c("read count"), format="simple", align = "l") |> kableExtra::kable_styling()) # 
  cat("\n", fill = T)
  cat(infoNote[["hashtags used"]], "\n\n")
  cat(infoNote[["CBs kept"]], "\n\n")
  print(kableExtra::kbl(as.data.frame(infoNote[["Classification results"]]), caption="Classification results", row.names=F, col.names=c("", "bead count"), format="simple", align = "l") |> kableExtra::kable_styling())
  cat("\n", fill = T)

  # include plots in report    
  cat("\n", fill = T)
  cat(paste0("![doublets](", file.path(dirnamePlot[i], "violinPlot_doublets.png"), "){width=45%}![singlets](", file.path(dirnamePlot[i], "tSNE_singlets.png"), "){width=45%}"))
  cat("\n", fill = T)
}

```


```{r demux_GT, results='asis', eval=!is.na(SHINYREPS_RUN_DEMUX) && SHINYREPS_RUN_DEMUX %in% c("demux_GT","demux_GT_noAssignment")}
cat("## De-Multiplexing by Genotype\n\n")

cat("\nSample multiplexing was applied by utilizing the natural genetic variation between samples. After cellranger analysis, the samples were demultiplexed using souporcell as outlined here: https://github.com/wheaton5/souporcell. Only mapped singlets are used for downstream processing. Note that the subsample IDs can be aligned to each other across samples (GEMwells) if coming from same individuals, but are not assigned to the experimental samples. For this we need external genetic information of each experimental sample to assign them to the clusters indentified by souporcell.\n")

if(file.exists(file.path(SHINYREPS_READAGGR_OUT, "demuxGT_overviewStatus.txt"))) {
 overviewStatus<- readr::read_tsv(file=file.path(SHINYREPS_READAGGR_OUT, "demuxGT_overviewStatus.txt"))
 kableExtra::kbl(overviewStatus, caption="Souporcell status", row.names=F, format="simple", align = "l") |> kableExtra::kable_styling()
}

```



## Quality control of cells

To assess if the sequenced libraries are usable and the RNA captured represents a meaningful fraction of the RNA present in the cell, we are focussing on the following factors:

* **Library size:** for cells with small library size the RNA was not efficiently captured.
* **Number of expressed genes:** few expressed genes suggest that a diverse transcript population was not captured.
* **Proportion of reads mapping to mitochondrial genes:** high proportion mean increased apoptosis and/or loss of cytoplasmatic RNA from lysed cells.

To remove outliers, these criteria may be filtered either for relative thresholds using the median absolute deviation (MAD) or by setting absolute threshold after inspecting the quality control plots.

```{r quality_plots_of_cells, results='asis'}

is.mito <- read.table(file=file.path(SHINYREPS_QC_BIOC_OUT, "is.mito.txt"), sep="\t", header=F)
cat("\n", sum(is.mito[,2]), "mitochrondrial genes identified.\n")
  
if(file.exists(file.path(SHINYREPS_QC_BIOC_OUT, "is.spikein.txt"))) {
  is.spikein <- read.table(file=file.path(SHINYREPS_QC_BIOC_OUT, "is.spikein.txt"), sep="\t", header=F)
  cat("\n", sum(is.spikein[,2]), "spike-in genes identified.\n")
} 

qc.frame <- read.table(file=file.path(SHINYREPS_QC_BIOC_OUT, "qc.frame.txt"), sep="\t", header=T)

# include ordered violin plots in report
filenamePlot <- tibble::tibble(file = list.files(file.path(SHINYREPS_QC_BIOC_OUT), pattern="^qc_violin_plot_.*\\.png$")) |>
  dplyr::filter(!stringr::str_detect(file, stringr::regex("filtered", ignore_case = TRUE))) |>  
  dplyr::mutate(
    priority = dplyr::case_when(
      stringr::str_detect(file, stringr::regex("sum",          ignore_case = TRUE)) ~ 1L,
      stringr::str_detect(file, stringr::regex("detected",     ignore_case = TRUE)) ~ 2L,
      stringr::str_detect(file, stringr::regex("Mito",         ignore_case = TRUE)) ~ 3L,
      stringr::str_detect(file, stringr::regex("spikein",      ignore_case = TRUE)) ~ 4L,
      stringr::str_detect(file, stringr::regex("scDblFinder",  ignore_case = TRUE)) ~ 5L,
      TRUE ~ 99L  # anything else comes after
    )
  ) |>
  dplyr::arrange(priority, file) |>    
  dplyr::pull(file)

knitr::include_graphics(path=file.path(SHINYREPS_QC_BIOC_OUT, filenamePlot))


```



**Top 2% biggest libraries (based on mapped reads on features)**

```{r top_perc_cells}
# Output the cells with a library size in the top 2%
if(file.exists(file.path(SHINYREPS_QC_BIOC_OUT, "highest.lib.size.txt"))) {
  highest.lib.size <- read.table(file.path(SHINYREPS_QC_BIOC_OUT, "highest.lib.size.txt"), sep="\t", header=T)
  DT::datatable(as.data.frame(highest.lib.size), caption="2% cells with the highest library size")
} 

```


```{r total_counts_per_plate_position, results='asis', eval= (SHINYREPS_SEQTYPE %in% c("MARSseq", "SmartSeq"))}

cat("\nOverview plate distribution\n")
filenamePlot <- list.files(file.path(SHINYREPS_QC_BIOC_OUT), pattern="^plate_distribution_plot_by_.*\\.png$")
if(length(filenamePlot)>0) {
  knitr::include_graphics(path=file.path(SHINYREPS_QC_BIOC_OUT, filenamePlot))
}

```


### Correlation plots for different features

```{r corr_plots}

# include plots in report
filenamePlot <- list.files(file.path(SHINYREPS_QC_BIOC_OUT), pattern="^scatterplot_.*\\.png$")
knitr::include_graphics(path=file.path(SHINYREPS_QC_BIOC_OUT, filenamePlot))

```

## Filtering out low quality cells

Filter criteria (see below) have been applied as selected.

```{r dropout_cells, results='asis'}

qc_thresholds <- readr::read_tsv(file=file.path(SHINYREPS_QC_BIOC_OUT, "qc_thresholds.txt")) |>
  kableExtra::kbl(caption="QC thresholds", row.names=F, format="simple") |> 
  kableExtra::kable_styling() |>
  print()

qcfailed <- readr::read_tsv(file=file.path(SHINYREPS_QC_BIOC_OUT, "qcfailed_overview.txt")) |>
  kableExtra::kbl(caption="Summary of cells that don't pass the QC", row.names=F, format="simple") |> 
  kableExtra::kable_styling() |>
  print()

# qc.drop <- read.table(file=file.path(SHINYREPS_QC_BIOC_OUT, "qc.drop.txt"), sep="\t", header=T) # not needed

# include ordered violin plots in report
cat("\nVioline plots with applied thresholds indicated:\n")
filenamePlot <- tibble::tibble(file = list.files(file.path(SHINYREPS_QC_BIOC_OUT), pattern="^qc_violin_plot_.*\\.png$")) |>
  dplyr::filter(stringr::str_detect(file, stringr::regex("filtered", ignore_case = TRUE))) |>  
  dplyr::mutate(
    priority = dplyr::case_when(
      stringr::str_detect(file, stringr::regex("sum",          ignore_case = TRUE)) ~ 1L,
      stringr::str_detect(file, stringr::regex("detected",     ignore_case = TRUE)) ~ 2L,
      stringr::str_detect(file, stringr::regex("Mito",         ignore_case = TRUE)) ~ 3L,
      stringr::str_detect(file, stringr::regex("spikein",      ignore_case = TRUE)) ~ 4L,
      stringr::str_detect(file, stringr::regex("scDblFinder",  ignore_case = TRUE)) ~ 5L,
      TRUE ~ 99L  # anything else comes after
    )
  ) |>
  dplyr::arrange(priority, file) |>   
  dplyr::pull(file)

knitr::include_graphics(path=file.path(SHINYREPS_QC_BIOC_OUT, filenamePlot))

```



## Filtering out low abundance genes

Average counts per gene should correlate with number of cells expressing it (see plot below). 
Low abundance genes are likely to be dominated by drop-out events (Poisson noise in different cells). They do not contain enough information for statistical inference, and may compromise accuracy of continuous approximations when fitting the data (edgeR biological coefficient of variation (BCV) estimation). Here, we filter out genes with no expression (i.e. zero count) in the specified proportion of the cells.

```{r remove_low_abundance_genes, results='asis'}

knitr::include_graphics(path=file.path(SHINYREPS_QC_BIOC_OUT, "low_abundance.png"))

low_abundance_count <- read.table(file=file.path(SHINYREPS_QC_BIOC_OUT, "low_abundance_count.txt"), sep="\t", header=F) 
kableExtra::kbl(t(low_abundance_count), caption="Removed low abundance genes", row.names=F, format="simple") |> kableExtra::kable_styling()

```



# Normalization of cell-specific biases
Normalization is required to eliminate these cell-specific differences in capture efficiency, prior to downstream quantitative analyses.

## Normalization by deconvolution

Size factors can be calculated with DESeq2 or edgeR, but these methods do not work well with single-cell data due to the dominance of low and zero counts. To overcome this, we pool counts from many cells to increase the size of the counts for accurate size factor estimation (Lun, Bach, and Marioni 2016). Pool-based size factors are then “deconvolved” into cell-based factors for normalization of each cell's expression profile. We use a pre-clustering step with quickCluster where cells in each cluster are normalized separately and the size factors are rescaled to be comparable across clusters. This avoids the assumption that most genes are non-DE across the entire population. Only a non-DE majority is required between pairs of clusters, which is a weaker assumption for highly heterogeneous populations.

Once we have computed the size factors, we use the logNormCounts function from scater to compute normalized expression values for each cell. This is done by dividing the count for each transcript with the appropriate size factor for that cell. The function also log-transforms the normalized values, creating a new logcounts assay. Technically, these are 'log-transformed normalized expression values' and are used for downstream analysis.

```{r size_factors_and_normalize, results='asis'}

if(as.logical(SHINYREPS_SPIKEIN_NORM)) {
  cat("\nSpike-in normalized size factors were used for normalisation: Spike-in normalization is based on the assumption that the same amount of spike-in RNA was added to each cell (Lun et al. 2017). Systematic differences in the coverage of the spike-in transcripts can only be due to cell-specific biases, e.g. in capture efficiency or sequencing depth. To remove these biases, we equalize spike-in coverage across cells by scaling with spike-in size factors. Spike-in normalization requires no assumption about the biology of the system (i.e., the absence of many DE genes). Instead, it assumes that the spike-in transcripts were (i) added at a constant level to each cell, and (ii) respond to biases in the same relative manner as endogenous genes. Practically, spike-in normalization should be used if differences in the total RNA content of individual cells are of interest and must be preserved in downstream analyses. For a given cell, an increase in its overall amount of endogenous RNA will not increase its spike-in size factor. This ensures that the effects of total RNA content on expression across the population will not be removed upon scaling.\n")
}
knitr::include_graphics(path=file.path(SHINYREPS_NORM_BIOC_OUT, "size_factors.png"))

```


## Top most highly expressed genes

The plot below shows the most highly expressed genes based on mean normalized counts. 

```{r highly_expr_genes}

filenamePlot <- list.files(file.path(SHINYREPS_NORM_BIOC_OUT), pattern="^top_.*expressed_genes\\.png$")
knitr::include_graphics(path=file.path(SHINYREPS_NORM_BIOC_OUT, filenamePlot))


```


# Identifying highly variable genes (HVGs)

The per-gene variation is quantified by computing the variance of the log-normalized expression values for each gene across all cells in the population (A. T. L. Lun, McCarthy, and Marioni 2016). This has an advantage in that the feature selection is based on the same log-values that are used for later downstream steps. In particular, genes with the largest variances in log-values will contribute the most to the Euclidean distances between cells. By using log-values here, we ensure that our quantitative definition of heterogeneity is consistent throughout the entire analysis.

Calculation of the per-gene variance is simple but feature selection requires modelling of the mean-variance relationship. The log-transformation does not achieve perfect variance stabilization, which means that the variance of a gene is driven more by its abundance than its underlying biological heterogeneity. To account for this effect, we use the modelGeneVar() function to fit a trend to the variance with respect to abundance across all genes.

At any given abundance, we assume that the expression profiles of most genes are dominated by random technical noise. Under this assumption, our trend represents an estimate of the technical noise as a function of abundance. We then break down the total variance of each gene into the technical component, i.e., the fitted value of the trend at that gene’s abundance; and the biological component, defined as the difference between the total variance and the technical component. This biological component represents the interesting variation for each gene and can be used as the metric for HVG selection.

Once we have quantified the per-gene variation, the next step is to select the subset of HVGs to use in downstream analyses. A larger subset will reduce the risk of discarding interesting biological signal by retaining more potentially relevant genes, at the cost of increasing noise from irrelevant genes that might obscure said signal.

```{r trendVar}

if(!is.na(SHINYREPS_BLOCKVAR_NORM)) {
  cat(SHINYREPS_BLOCKVAR_NORM, "used as blocking factor for estimating highly variable genes.\n")
}
if(as.numeric(SHINYREPS_HVG_N)>1) { # absolute number of top HVGs to report
  cat("Top", SHINYREPS_HVG_N, "HVGs used for downstream analysis\n")
} else { # proportion of genes to report as HVGs
  cat("Top", SHINYREPS_HVG_N, "portion of variable genes used as HVGs for downstream analysis\n")
}

filenamePlot <- list.files(file.path(SHINYREPS_NORM_BIOC_OUT), pattern="^top_.*highly_variable_genes\\.png$")
knitr::include_graphics(path=file.path(SHINYREPS_NORM_BIOC_OUT, filenamePlot))

```


# Using HVGs for further data exploration

## PCA based on significantly HVGs

Principal components analysis (PCA) discovers axes in high-dimensional space that capture the largest amount of variation. The variance captured by an axis is defined as the variance in the positions of cells along that line. In PCA, the first axis (or principal component, PC) is chosen such that it maximizes this variance. The next PC is chosen such that it is orthogonal to the first and captures the greatest remaining amount of variation, and so on.

```{r hvg_pca, results='asis'}

if(SHINYREPS_PCA_COMPONENTS=="") {
  cat("As no number of PCA components were specified, the number of PCs was selected from the elbow plot below.")
  filenamePlot <- list.files(file.path(SHINYREPS_NORM_BIOC_OUT), pattern="^elbow_plot_for_PC_variance\\.png$")
  knitr::include_graphics(path=file.path(SHINYREPS_NORM_BIOC_OUT, filenamePlot))
}
filenamePlot <- list.files(file.path(SHINYREPS_NORM_BIOC_OUT), pattern="^dimred_plot_PCA.*\\.png$")
knitr::include_graphics(path=file.path(SHINYREPS_NORM_BIOC_OUT, rev(filenamePlot)))

```


```{r TSNE_plot_various_perplexities, results='asis'}

filenamePlot <- list.files(file.path(SHINYREPS_NORM_BIOC_OUT), pattern="^dimred_plot_TSNE.*\\.png$")

if(length(filenamePlot)>0) {
    
  cat("## Identification of sub-populations with t-SNE 

Another widely used approach is the t-stochastic neighbour embedding (t-SNE) method (Van der Maaten & Hinton, 2008). t-SNE  tends  to  work  better  than  PCA  for  separating  cells  in  more  diverse  populations.  This  is  because  the former can directly capture non-linear relationships in high-dimensional space, whereas the latter must represent them (suboptimally) as linear components. However, this improvement comes at the cost of more computational effort and complexity. It is advisable to test different settings of the perplexity parameter as this will affect the distribution of points in the low-dimensional space. The perplexity can be interpreted as a smooth measure of the effective number of neighbors. Low perplexities will favor resolution of finer structure, possibly to the point that the visualization is compromised by random noise. Typical values are between 5 and 50. Here, a perplexity of", paste(SHINYREPS_PERPLEXITY, collapse=", "), "was selected.

A major weakness of t-SNE is that the cost function is not convex, as a result of which several optimization parameters need to be chosen. The constructed solutions depend on these choices of optimization parameters and may be different each time t-SNE is run from an initial random configuration of map points. Finally, it is unwise to read too much into the relative sizes and positions of the visual clusters. t-SNE will inflate dense clusters and compress sparse ones, such that we cannot use the size as a measure of subpopulation heterogeneity. In addition, t-SNE is not obliged to preserve the relative locations of non-neighboring clusters, such that we cannot use their positions to determine relationships between distant clusters.\n")
  
  knitr::include_graphics(path=file.path(SHINYREPS_NORM_BIOC_OUT, rev(filenamePlot)))
} 

```


```{r UMAP_plot, results='asis'}

filenamePlot <- list.files(file.path(SHINYREPS_NORM_BIOC_OUT), pattern="^dimred_plot_UMAP.*\\.png$")

if(length(filenamePlot)>0) {
    
  cat("## Identification of sub-populations with UMAP 

Uniform manifold approximation and projection (UMAP) is a nonlinear dimensionality reduction technique to identify sub-populations in expression data. Here, UMAP dimensions are calculated with", paste(SHINYREPS_PERPLEXITY, collapse=", "), "nearest neighbors.\n")
  
  knitr::include_graphics(path=file.path(SHINYREPS_NORM_BIOC_OUT, rev(filenamePlot)))
} 

```


## Checking for confounding factors 

```{r find_cell_cycle, results='asis'}


if(file.exists(file.path(SHINYREPS_NORM_BIOC_OUT, "cell_cycle_phase_assignments.txt"))) {
  
  cat("### Classification and normalization of cell cycle phase

We use the prediction method described by Scialdone et al. (2015) to classify cells into cell cycle phases based on the gene expression data. Pre-trained classifiers are available in scran for human and mouse data. Cells are classified as being in G1 phase if the G1 score is above 0.5 and greater than the G2/M score, in G2/M phase if the G2/M score is above 0.5 and greater than the G1 score, and in S phase if neither score is above 0.5.

Remark for adjustment: in routine scRNA-seq analyses it is not recommended to adjust for cell cycle. Compared to other differences between cell types it is a minor factor of variation and any attempt at removal would also need to assume that the cell cycle effect is orthogonal to other biological processes. For example, regression would potentially remove interesting signal if cell cycle activity varied across clusters or conditions. Cell cycle adjustment may be performed on an as-needed basis in populations with clear cell cycle effects.\n")

  assignments <- read.table(file=file.path(SHINYREPS_NORM_BIOC_OUT, "cell_cycle_phase_assignments.txt"), sep="\t", header=T)
  cat(sum(is.na(assignments$phases)), "out of", length(assignments$phases),
  "cells could not be assigned to a cell cycle phase.\n", fill=TRUE)

  if(file.exists(file.path(SHINYREPS_NORM_BIOC_OUT, "cell_cycle_phase_summary_table.txt"))) {
    ccptable <- read.table(file=file.path(SHINYREPS_NORM_BIOC_OUT, "cell_cycle_phase_summary_table.txt"), sep="\t", header=T) |>
      kableExtra::kbl(caption="Cell cycle phases", align = "l", format="simple") |> 
      kableExtra::kable_styling() |>
      print()
    cat("\n")
  
    knitr::include_graphics(path=file.path(SHINYREPS_NORM_BIOC_OUT, "cell_cycle_phase_score_plot.png"))
  }
} 

```


### Identify explanatory variables 

We check whether there are experimental batch factors that contribute substantially to the heterogeneity of gene expression. If so, the factor may be specified as blocking variable for HVG and marker detection and in differential expression analysis.

```{r explanatory_variables, results='asis'}

if(file.exists(file.path(SHINYREPS_NORM_BIOC_OUT, "explanatory_variables_density_plot.png"))) {
  knitr::include_graphics(path=file.path(SHINYREPS_NORM_BIOC_OUT, "explanatory_variables_density_plot.png"))
} 

filenamePlot <- list.files(file.path(SHINYREPS_NORM_BIOC_OUT), pattern="^explanatory_variables_scatter_plot.*\\.png$")
if(length(filenamePlot)>0) {
  cat("\nPCA plots of top 500 genes colored by potential confounder variables\n\n")  
  knitr::include_graphics(path=file.path(SHINYREPS_NORM_BIOC_OUT, filenamePlot))
} 

```


# Clustering

## Graph-based clustering with igraph

Graph-based clustering is a flexible and scalable technique for clustering large scRNA-seq datasets. We first build a graph where each node is a cell that is connected to its nearest neighbours in the high-dimensional space. Edges are weighted based on the similarity between the cells involved, with higher weight given to cells that are more closely related. We then apply algorithms to identify communities of cells that are more connected to cells in the same community than they are to cells of different communities. Each community represents a cluster that we can use for downstream interpretation. 

Graph construction avoids making strong assumptions about the shape of the clusters or the distribution of cells within each cluster, compared to other methods. k is the number of nearest neighbors used to construct the graph. This controls the resolution of the clustering where higher k yields a more inter-connected graph and broader clusters. Users can exploit this by experimenting with different values of k to obtain a satisfactory resolution.

```{r clustering_graphbased, results='asis'}

# collect all Cell counts per sample tables for all igraph sub-directories (including kmeans pre-clustering)
clusterTables <- list.files(SHINYREPS_CLUSTER_DIR, pattern = "^cluster_.*igraph.*cellCounts_per_sample\\.txt$", full.names = TRUE, recursive = TRUE)
cl_avail <- basename(dirname(clusterTables))

if(length(cl_avail)>0) {
  tab <- purrr::map(cl_avail, function(cl) {
    
    cat(paste("\n\n###", cl, "\n")) 

    cellcountFile <- list.files(file.path(SHINYREPS_CLUSTER_DIR, cl), pattern = "^cluster_.*igraph.*cellCounts_per_sample\\.txt$", full.names = TRUE) |>
      readr::read_tsv() |>
      dplyr::arrange(dplyr::pick(1)) |>
      kableExtra::kbl(caption=paste("Cell counts per sample for", cl), align = "l", format="simple") |> 
      kableExtra::kable_styling() |>
      print()

    cat("\n")
    filenamePlot <- list.files(file.path(SHINYREPS_CLUSTER_DIR, cl), pattern = "^cluster_.*igraph.*\\.png$", full.names = TRUE)
    filenamePlot <- filenamePlot[!grepl("_approx_silhouette_width", filenamePlot)]
    filenamePlot <- rev(filenamePlot[!grepl("_split_by_group", filenamePlot)])
    md <- paste0("![](", filenamePlot, ")", collapse = " ")
    cat(md, "\n\n")  
  })
}

```


## Hierarchical clustering

Hierarchical clustering arranges samples into a hierarchy based on their relative similarity to each other. Most implementations do so by joining the most similar samples into a new cluster, then joining similar clusters into larger clusters, and so on, until all samples belong to a single cluster. This process yields obtain a dendrogram that defines clusters with progressively increasing granularity.  

In the context of scRNA-seq, the main advantage of hierarchical clustering lies in the production of the dendrogram, which is a rich summary that quantitatively captures the relationships between subpopulations at various resolutions. Cutting the dendrogram at high resolution is also guaranteed to yield clusters that are nested within those obtained at a low-resolution cut. In practice, hierarchical clustering is too slow to be used for big scRNA-seq datasets. Therefore, you may try a two-step approach to perform hierarchical clustering on the representative centroids obtained by an initial k-means vector quantization step.

```{r clustering_hierarchical, results='asis'}

# collect all Cell counts per sample tables for all hclust sub-directories (including kmeans pre-clustering)
clusterTables <- list.files(SHINYREPS_CLUSTER_DIR, pattern = "^cluster_.*hclust.*cellCounts_per_sample\\.txt$", full.names = TRUE, recursive = TRUE)
cl_avail <- basename(dirname(clusterTables))

if(length(cl_avail)>0) {
  tab <- purrr::map(cl_avail, function(cl) {
    
    cat(paste("\n\n###", cl, "\n")) 

    cellcountFile <- list.files(file.path(SHINYREPS_CLUSTER_DIR, cl), pattern = "^cluster_.*hclust.*cellCounts_per_sample\\.txt$", full.names = TRUE) |>
      readr::read_tsv() |>
      dplyr::arrange(dplyr::pick(1)) |>
      kableExtra::kbl(caption=paste("Cell counts per sample for", cl), align = "l", format="simple") |> 
      kableExtra::kable_styling() |>
      print()

    cat("\n")
    filenamePlot <- list.files(file.path(SHINYREPS_CLUSTER_DIR, cl), pattern = "^cluster_.*hclust.*\\.png$", full.names = TRUE)
    filenamePlot <- filenamePlot[!grepl("_approx_silhouette_width", filenamePlot)]
    filenamePlot <- rev(filenamePlot[!grepl("_split_by_group", filenamePlot)])
    md <- paste0("![](", filenamePlot, ")", collapse = " ")
    cat(md, "\n\n")  
  })
}

```


## k-means clustering

Vector quantization partitions observations into groups where each group is associated with a representative point, i.e., vector in the coordinate space. This is a type of clustering that primarily aims to compress data by replacing many points with a single representative. The representatives can then be treated as “samples” for further analysis, reducing the number of samples and computational work in later steps like, e.g., trajectory reconstruction (Ji and Ji 2016). This approach will also eliminate differences in cell density across the expression space, ensuring that the most abundant cell type does not dominate downstream results.k-means clustering is a classic vector quantization technique that divides cells into k clusters. Each cell is assigned to the cluster with the closest centroid, which is done by minimizing the within-cluster sum of squares using a random starting configuration for the k centroids.

```{r kmeans_clustering, results='asis'}

# collect all Cell counts per sample tables for all kmeans sub-directories (including kmeans pre-clustering)
clusterTables <- list.files(SHINYREPS_CLUSTER_DIR, pattern = "^cluster_kmeans.*cellCounts_per_sample\\.txt$", full.names = TRUE, recursive = TRUE)
cl_avail <- basename(dirname(clusterTables))

if(length(cl_avail)>0) {
  tab <- purrr::map(cl_avail, function(cl) {
    
    cat(paste("\n\n###", cl, "\n")) 

    cellcountFile <- list.files(file.path(SHINYREPS_CLUSTER_DIR, cl), pattern = "^cluster_kmeans.*cellCounts_per_sample\\.txt$", full.names = TRUE) |>
      readr::read_tsv() |>
      dplyr::arrange(dplyr::pick(1)) |>
      kableExtra::kbl(caption=paste("Cell counts per sample for", cl), align = "l", format="simple") |> 
      kableExtra::kable_styling() |>
      print()

    cat("\n")
    filenamePlot <- list.files(file.path(SHINYREPS_CLUSTER_DIR, cl), pattern = "^cluster_kmeans.*\\.png$", full.names = TRUE)
    filenamePlot <- filenamePlot[!grepl("_(igraph|hclust)", filenamePlot)] # exclude plots from other clustering types which use kmeans pre-clustering
    filenamePlot <- filenamePlot[!grepl("_approx_silhouette_width", filenamePlot)]
    filenamePlot <- rev(filenamePlot[!grepl("_split_by_group", filenamePlot)])
    md <- paste0("![](", filenamePlot, ")", collapse = " ")
    cat(md, "\n\n")  
  })
}

```



```{r plot_selected_genes_per_cluster, results='asis', fig.show='hold', out.width='49%'}

filenamePlot <- list.files(file.path(SHINYREPS_EXPRPLOT_DIR), pattern="_expressionplot_by_UMAP.*\\.png$", full.names = TRUE)

if(length(filenamePlot)>0) {
  cat("# Expression plot of selected genes\n")
  filenamePlot <- filenamePlot[!grepl("_split_by_group", filenamePlot)]
  knitr::include_graphics(path=file.path(filenamePlot))
} 

```


# Doublet detection

The methods applied here are complementary to doublets identified via cell hashes and SNPs in multiplexed samples: while hashing/genotypes can identify doublets formed by cells of the same type (homotypic doublets) from two samples loaded to the same GEM well, which are often nearly undistinguishable from real cells transcriptionally (and hence generally unidentifiable through the present package), it cannot identify doublets made by cells of the same sample, even if they are heterotypic (formed by different cell types). Instead, the methods presented here are primarily geared towards the identification of heterotypic doublets, which for most purposes are also the most critical ones.

```{r doublets, results='asis', echo=FALSE, warning=FALSE}
doupletScorePlot <- list.files(file.path(SHINYREPS_NORM_BIOC_OUT), pattern="doublet_score_by_UMAP.*\\.png", full.names = TRUE) # independent of clustering
doupletScorePlot <- doupletScorePlot[!grepl("_split_by_(group|sample)", doupletScorePlot)] ## use all UMAP variants but not the split ones

if(length(doupletScorePlot)>0) {
  cat("## Doublet detection by simulation\n\n")
  cat("The scDblFinder function (Germain et al. 2021) combines the simulated doublet density with an iterative classification scheme. For each observed cell, an initial score is computed by combining the fraction of simulated doublets in its neighborhood with another score based on co-expression of mutually exclusive gene pairs (Bais and Kostka 2020). A threshold is chosen that best distinguishes between the real and simulated cells, allowing us to obtain putative doublet calls among the real cells. The threshold and scores are then iteratively refined by training a classifier on the putative calls with a variety of metrics to characterize the doublet neighborhood. These metrics include the low-dimensional embeddings in PC space, the fraction of doublets among the k nearest neighbors for a variety of k, the distance to the closest real cell, the expected within-cluster doublet formation rate, the observed number of cells in each cluster, and so on. The classifier distills all of these metrics into a single score based on their learnt importance.\nSimply removing cells with high doublet scores will not be sufficient to eliminate real doublets from the data set. In some cases, only a subset of the cells in the putative doublet cluster actually have high scores, and removing these would still leave enough cells in that cluster to mislead downstream analyses. In fact, even defining a threshold on the doublet score is difficult as the interpretation of the score is relative. There is no general definition for a fixed threshold above which libraries are to be considered doublets. We recommend interpreting the scores in the context of cluster annotation. All cells from a cluster with a large average doublet score should be considered suspect, and close neighbors of problematic clusters should also be treated with caution.")
  knitr::include_graphics(path=c(doupletScorePlot))
} 

# collect all doublet_detection txt files in clusterdir sub-directories
files_doubl <- list.files(SHINYREPS_CLUSTER_DIR, pattern = "_doublet_detection_by_cluster.txt$", full.names = TRUE, recursive = TRUE)
cl_avail <- gsub("_doublet_detection_by_cluster.txt", "", basename(files_doubl))

if(length(cl_avail)>0) {
  cat("\n\n## Doublet detection by clusters\n\n")
  cat("The findDoubletClusters function from the scDblFinder package identifies clusters with expression profiles lying between two other clusters (Bach et al. 2017, https://doi.org/10.1038/s41467-017-02001-5). We consider every possible triplet of clusters consisting of a query cluster and two putative “source” clusters. Under the null hypothesis that the query consists of doublets from the two sources, we compute the number of genes (num.de) that are differentially expressed in the same direction in the query cluster compared to both of the source clusters. Such genes would be unique markers for the query cluster and provide evidence against the null hypothesis (for a doublet we would expect an intermediate gene expression respective to the 2 source clusters). For each query cluster, the best pair of putative sources is identified based on the lowest num.de. 
Clusters are then ranked by num.de where those with the few unique genes are more likely to be composed of doublets. Further characteristics indicating potential doublet clusters comprise a reasonable proportion of cells in the cluster (given in 'prop') with respect to the experimental protocol. The function also reports the ratio of the median library size in each source to the median library size in the query (lib.size fields). For a cluster made of doublets, the library sizes of the source clusters should be below that of the query cluster, i.e. lib.size values below unity. This assumes that the doublet cluster will contain more RNA and have more counts than either of the two source clusters. The top gene with the lowest adjusted p-value against the doublet hypothesis is given in the 'best' column. The reported p.value is of little use in a statistical sense, and is only provided for inspection.")

  dbl <- purrr::map(cl_avail, function(cl) {
    cat("\n\n### ", cl, "\n\n")
    doubletTablePath <- files_doubl[grepl(cl, files_doubl)]
    dtable <- readr::read_tsv(doubletTablePath) |>
      kableExtra::kbl(caption=paste("Doublet detection with clusters for ", cl), align = "l", format="simple") |> 
      kableExtra::kable_styling()|>
      print()
  })
}


```


# Detect marker genes for each cluster

To interpret our clustering results, we identify the genes that drive separation between clusters. These marker genes allow us to assign biological meaning to each cluster based on their functional annotation. This approach involves testing for differential expression between clusters. If a gene is strongly DE between clusters, it is likely to have driven the separation of cells in the clustering algorithm. Our general strategy is using the the scoreMarkers function from scran package to compare each pair of clusters and compute scores quantifying the differences in the expression distributions between clusters. We deliberately use pairwise comparisons rather than comparing each cluster to the average of all other cells. The latter approach is sensitive to the population composition, which introduces an element of unpredictability to the marker sets due to variation in cell type abundances. (In the worst case, the presence of one subpopulation containing a majority of the cells will drive the selection of top markers for every other cluster, pushing out useful genes that can distinguish between the smaller sub-populations.) Moreover, pairwise comparisons naturally provide more information to interpret of the utility of a marker, e.g., by providing log-fold changes to indicate which clusters are distinguished by each gene.

The results tables within the results files (not included in html report) show for each cluster the self.average (the mean log-expression for this cluster), other.average (the grand mean across all other clusters), self.detected (the proportion of cells with detected expression in this cluster), other.detected (the mean detected proportion across all other clusters) and a variety of effect size summaries (AUC, logFC.cohen, logFC.detected) generated from all pairwise comparisons involving this cluster. For each cluster, we can then rank candidate markers based on one of these effect size summaries. The heatmaps given below show the centered average log-expression values for the top potential marker genes of each cluster.


```{r findmarkers_per_cluster, results='asis', echo=FALSE, warning=FALSE}
#, fig.show='hold', out.width='49%'
markerHeatmaps <- list.files(file.path(SHINYREPS_FINDMARKERS_BIOC_OUT), pattern="^marker_genes.*ranked_by_.*heatmap.*\\.png", full.names = TRUE, recursive = TRUE) 
cl_avail <- basename(unique(dirname(markerHeatmaps)))

if(length(cl_avail)>0) {
  
  if(!is.na(SHINYREPS_BLOCKVAR_MARKER)) {
  cat(SHINYREPS_BLOCKVAR_MARKER, "used as blocking factor for marker gene detection. Each pairwise comparison between clusters is performed separately in each level of the blocking factor. By comparing within each batch, we cancel out any batch effects so that they are not conflated with the biological differences between subpopulations. The effect sizes are then averaged across batches to obtain a single value per comparison, using a weighted mean that accounts for the number of cells involved in the comparison in each batch. A similar correction is applied to the mean log-expression and proportion of detected cells inside and outside each cluster.\n")
  }

  cat("\n\n## Gene marker heatmaps per cluster\n\n")

  dbl <- purrr::walk(cl_avail, function(cl) {
    cat("\n\n### ", cl, "\n\n")
    heatmapPath <- stringr::str_sort(markerHeatmaps[grepl(cl, markerHeatmaps)], numeric = TRUE)
    md <- paste0("![](", heatmapPath, "){width=49%}", collapse = " ")
    cat(md, "\n\n")  # images side-by-side
    })
}

```


```{r findmarkers_GOenrich, results='asis', echo=FALSE, warning=FALSE}

GOTables <- list.files(file.path(SHINYREPS_FINDMARKERS_BIOC_OUT), pattern="^GOenrichment.*ranked_by_.*\\.txt", full.names = TRUE, recursive = TRUE) 
cl_avail <- basename(unique(dirname(GOTables)))

if(length(cl_avail)>0) {
  cat("\n\n## GO enrichment of marker genes per cluster\n\n")

  cat("\nWe perform a gene set enrichment analysis on the marker genes defining each cluster. This identifies the pathways and processes that are (relatively) active in each cluster based on upregulation of the associated genes compared to other clusters. We will use gene sets defined by the Gene Ontology (GO) project, which describe a comprehensive range of biological processes and functions. We use the top", SHINYREPS_TOPMARKER4GO, "marker genes and apply the goana function from the limma package. This performs a hypergeometric test to identify GO terms that are overrepresented in our marker subset. We keep only biological process terms that are not overly general (<=500 genes) and which are significantly enriched", paste0("(p<", SHINYREPS_MARKERGO_PTHRESHOLD,")."), "\n\n")
  
  dbl <- purrr::map(cl_avail, function(cl) {
    cat("\n\n### ", cl, "\n\n")
    GOTables_cl <- stringr::str_sort(GOTables[grepl(cl, GOTables)], numeric = TRUE)
    
    dblcl <- purrr::map(GOTables_cl, function(t) {
      dtable <- readr::read_tsv(t) |>
        dplyr::slice(1:10) |>
        kableExtra::kbl(caption=paste("GO enrichment of marker genes for ", gsub("GOenrichment.*_", "", gsub("\\.txt$", "", basename(t)))), align = "l", format="simple") |>
        kableExtra::kable_styling() |>
        print()
    })
  })
}

```


# Cell type annotation

## scType

The scType tool (PMID: 35273156) is used to perform the marker-based cell type annotation per cluster. This tool uses positive and negative marker genes to annotate a cluster to a specific celltype. The marker gene sets can be collected from scTypes own marker database or from other databases like CellMarkerDB, Human Cell Atlas, PangaloDB or from literature. When a cluster contains scType score (which is used to annotate clusters) lower than one-fourth of the number of cells in the cluster, the cluster is labelled as unknown. 

```{r scType_anno, results='asis'}

# collect all overview tables
scTypeTables <- list.files(SHINYREPS_CTANNO_DIR, pattern = "^anno_scType_.*overview\\.txt$", full.names = TRUE, recursive = TRUE)
anno_avail <- basename(dirname(scTypeTables))

if(length(anno_avail)>0) {
  tab <- purrr::map(anno_avail, function(anno) {
    
    cat(paste("\n\n###", anno, "\n")) 

    overviewFile <- list.files(file.path(SHINYREPS_CTANNO_DIR, anno), pattern = "^anno_scType_.*overview\\.txt$", full.names = TRUE) |>
      readr::read_tsv() |>
      dplyr::arrange(dplyr::pick(1)) |>
      kableExtra::kbl(caption=paste("Cell type annotation for", anno), align = "l", format="simple") |> 
      kableExtra::kable_styling() |>
      print()

    cat("\n")
    cellcountFile <- list.files(file.path(SHINYREPS_CTANNO_DIR, anno), pattern = "^anno_scType_.*cell_counts_per_celltype\\.txt$", full.names = TRUE) |>
      readr::read_tsv() |>
      dplyr::arrange(dplyr::pick(1)) |>
      kableExtra::kbl(caption=paste("Cell counts per sample for", anno), align = "l", format="simple") |> 
      kableExtra::kable_styling() |>
      print()

    cat("\n")
    filenamePlot <- list.files(file.path(SHINYREPS_CTANNO_DIR, anno), pattern = "^anno_scType_.*by_UMAP.*\\.png$", full.names = TRUE)
    filenamePlot <- rev(filenamePlot[!grepl("_split_by_group", filenamePlot)])
    md <- paste0("![](", filenamePlot, ")", collapse = " ")
    cat(md, "\n\n")  
  })
}

```


# Differential expression analysis per cluster

Here we test for changes in gene expression between conditions for cells of the same type (cluster or cell type) that are present in both conditions using pseudo-bulk samples. Motivations behind the use of pseudo-bulking (for every gene, merge signal of all cells belonging to the same cluster and sample):

- Larger counts are more amenable to standard DE analysis pipelines designed for bulk RNA-seq data. Normalization is more straightforward and certain statistical approximations are more accurate.
- Collapsing cells into samples reflects the fact that our biological replication occurs at the sample level (Lun and Marioni 2017). Each sample is represented no more than once for each condition, avoiding problems from unmodelled correlations between samples. Supplying the per-cell counts directly to a DE analysis pipeline would imply that each cell is an independent biological replicate, which is not true from an experimental perspective. 
- Variance between cells within each sample is masked, provided it does not affect variance across (replicate) samples. This avoids penalizing DEGs that are not uniformly up- or down-regulated for all cells in all samples of one condition. Masking is generally desirable as DEGs - unlike marker genes - do not need to have low within-sample variance to be interesting, e.g., if the treatment effect is consistent across replicate populations but heterogeneous on a per-cell basis. 
    
The DE analysis will be performed using quasi-likelihood (QL) methods from the edgeR package (Robinson, McCarthy, and Smyth 2010; Chen, Lun, and Smyth 2016). This uses a negative binomial generalized linear model (NB GLM) to handle overdispersed count data in experiments with limited replication. We test for differences in expression using glmQLFTest(). 

```{r diff_expression, results='asis'}

# collect all overview tables
deOverview <- list.files(SHINYREPS_DE_OUT, pattern = "^de_.*sign_genes\\.txt$", full.names = TRUE, recursive = TRUE)
de_avail <- basename(unique(dirname(deOverview)))
contrasts <- readr::read_tsv(SHINYREPS_CONTRASTS)

# set up combinations of parameter
params <- tidyr::expand_grid( 
  de = de_avail, 
  cn = contrasts$contrast.name
)

if(length(anno_avail)>0) {
  cat(paste("\n## Pseudo-buk DE analysis\n")) 
  
  cat(paste0("As in bulk RNA-seq, we remove samples with very low library sizes as step of pre-processing. For the pseudo-bulk samples, this is equivalent to removing label-sample combinations that have very few (here: <", SHINYREPS_MINCLUSTERSIZE_DE, ") cells. We also remove genes that are lowly expressed using the filterByExpr function from edgeR. This reduces computational work, improves the accuracy of mean-variance trend modelling and decreases the severity of the multiple testing correction. DEGs are tested for sigificance applying a log2-foldchange threshold of ", SHINYREPS_LFCTHRESHOLD_DE, " and are considered significant at a false discovery rate of ", SHINYREPS_FDRTHRESHOLD_DE, ".\n"))
  
  kableExtra::kbl(contrasts, caption=paste("contrasts analyzed"), align = "l", format="simple") |> 
    kableExtra::kable_styling() |> 
    print()
  
  tab <- purrr::pmap(params, function(de, cn) {
    
    cat(paste("\n\n###", de, "for contrast:", cn, "\n")) 

    overviewFile <- list.files(file.path(SHINYREPS_DE_OUT, de), pattern = paste0("^de_.*", cn, "_overview_sign_genes\\.txt$"), full.names = TRUE) |>
      readr::read_tsv() |>
      dplyr::arrange(dplyr::pick(1)) |>
      kableExtra::kbl(caption=paste("Overview significant genes for", de, "contrast", cn), align = "l", format="simple") |> 
      kableExtra::kable_styling() |>
      print()
    
    deFiles <- stringr::str_sort(list.files(file.path(SHINYREPS_DE_OUT, de), pattern = paste0("^de_.*", cn, "_cluster.*\\.txt$"), full.names = TRUE), numeric = TRUE)

    tab_de <- purrr::map(deFiles, function(f) {
    
      deFile <- readr::read_tsv(f) |>
        dplyr::slice(1:10) |>
        kableExtra::kbl(caption=paste("differential expressed genes for", cn, "cluster", gsub("^.*_cluster", "", gsub("\\.txt$", "", basename(f)))), align = "l", format="simple") |> 
        kableExtra::kable_styling() |>
        print()
    })
  })
}

```


```{r DE_GOenrich, results='asis', echo=FALSE, warning=FALSE}

GOTables <- list.files(file.path(SHINYREPS_DE_OUT), pattern="^GOenrichment.*\\.txt", full.names = TRUE, recursive = TRUE) 
de_avail <- basename(unique(dirname(GOTables)))

# set up combinations of parameter
params <- tidyr::expand_grid( 
  de = de_avail, 
  cn = contrasts$contrast.name
)

if(length(de_avail)>0) {
  cat("\n\n## GO enrichment of DE genes per cluster\n\n")

  cat("\nWe perform a gene set enrichment analysis on the DE genes defining each cluster. This identifies the pathways and processes that are (relatively) active in each cluster based on upregulation of the associated genes compared to other clusters. We will use gene sets defined by the Gene Ontology (GO) project, which describe a comprehensive range of biological processes and functions. We use the top", SHINYREPS_TOPDE4GO, "DE genes and apply the goana function from the limma package. This performs a hypergeometric test to identify GO terms that are overrepresented in our DE gene subset. We keep only biological process terms that are not overly general (<=500 genes) and which are significantly enriched", paste0("(p<", SHINYREPS_DEGO_PTHRESHOLD,")."), "\n\n")
  
  tab <- purrr::pmap(params, function(de, cn) {
    
    cat(paste("\n\n###", de, "for contrast:", cn, "\n")) 
    
    GOTables_de <- stringr::str_sort(list.files(file.path(SHINYREPS_DE_OUT, de), pattern = paste0("^GOenrichment_.*", cn, "_cluster.*\\.txt$"), full.names = TRUE), numeric = TRUE)

    tab_go <- purrr::map(GOTables_de, function(f) {
      GOTable_de <- readr::read_tsv(f)
      if (nrow(GOTable_de) == 0) return(invisible(NULL)) # skip empties
      GOTable_de <- dplyr::slice_head(GOTable_de, n = 10) |>
        kableExtra::kbl(caption=paste("GO enrichment of DEGs for", cn, "cluster", gsub("^.*_cluster", "", gsub("\\.txt$", "", basename(f)))), align = "l", format="simple") |>
        kableExtra::kable_styling() |>
        print()
    })
  })
}

```


# Used tools and versions for this analysis

The following tools were used for data processing:

```{r ToolVersions_paragraph, echo=F, results='asis', error=F, warning=F, message=F}
cat(Toolhelper.ToolVersions(), sep="\n")
```

</div>

